{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c835dcd0-c569-438c-8186-7bd9140bf297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getcwd().split('/')[-1] == 'notebooks':\n",
    "    os.chdir(os.pardir)\n",
    "\n",
    "import deepxde as dde\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams.update({'text.usetex': True,\n",
    "                     'text.latex.preamble': r'\\usepackage{amsmath}',\n",
    "                     'font.family': 'serif'})\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style='ticks', font='serif')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b606a09e-1a90-4a4b-959e-8b8f592e573c",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c5ae9c-b9c4-467d-8dea-361c8f912f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PROC_DATA = os.path.join('data', 'processed')\n",
    "syn_data = pd.read_csv(os.path.join(PATH_PROC_DATA, 'pDeltaT_synthetic.csv'))\n",
    "\n",
    "features = ['d [mm]', 'f [GHz]', 'psPDtot_1 [W/m2]', 'psPDtot_4 [W/m2]']\n",
    "target = 'pDeltaT * 100 [Â°C]'\n",
    "X = syn_data[features]\n",
    "y = syn_data[target] / 100\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled,\n",
    "                                                    y.to_numpy()[:, np.newaxis],\n",
    "                                                    test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbfb57c-db48-4cf6-947c-c22b5f388140",
   "metadata": {},
   "source": [
    "## Training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3c5141-c6b4-47bb-98f0-1d596c769f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dde.data.DataSet(X_train=X_train,\n",
    "                        X_test=X_test,\n",
    "                        y_train=y_train,\n",
    "                        y_test=y_test)\n",
    "\n",
    "layer_size = [4] + [256] * 3 + [1]\n",
    "activation = 'relu'\n",
    "initializer = 'Glorot normal'\n",
    "net = dde.nn.FNN(layer_size, activation, initializer)\n",
    "\n",
    "model = dde.Model(data, net)\n",
    "\n",
    "optimizer = 'adam'\n",
    "learning_rate = 1e-3\n",
    "model.compile(optimizer=optimizer,\n",
    "              lr=learning_rate,\n",
    "              metrics=['l2 relative error'])\n",
    "try:\n",
    "    print('Trying to restore the neural network...')\n",
    "    model.restore(os.path.join('models', '03_neural_network-500000.pt'))\n",
    "    print('Restoring successful.')\n",
    "    plot_loss = False\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print('Restoring failed. Training the neural network...')\n",
    "\n",
    "    iterations = 500_000\n",
    "    batch_size = 32\n",
    "    display_every = int(iterations/10)\n",
    "    start = timer()\n",
    "    loss_history, train_state = model.train(iterations=iterations,\n",
    "                                            batch_size=batch_size,\n",
    "                                            display_every=display_every)\n",
    "    end = timer()\n",
    "    elapsed = start - end\n",
    "    print(f'Training finished in {elapsed:.2f} s.')\n",
    "    save_path = model.save(os.path.join('models', '03_neural_network'))\n",
    "    print(f'Model saved ({save_path}).')\n",
    "    plot_loss = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a3e2c5-d8c2-4327-b975-75a5112ef448",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_loss:\n",
    "    cs = sns.color_palette('rocket', 3)\n",
    "    dashes = [(3, 1), (1, 1)]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4.5, 4))\n",
    "    _x = np.arange(len(loss_history.loss_train)) * display_every\n",
    "    ax.plot(_x, loss_history.loss_train, '-', c=cs[0], lw=2,\n",
    "            label='train loss')\n",
    "    ax.plot(_x, loss_history.loss_test, dashes=dashes[0], c=cs[1], lw=2,\n",
    "            label='test loss')\n",
    "    ax.plot(_x, loss_history.metrics_test, dashes=dashes[1], c=cs[2], lw=2,\n",
    "            label='test metrics')\n",
    "    ax.legend()\n",
    "    ax.set(xlabel='', ylabel='',\n",
    "           #xscale='log',\n",
    "           yscale='log',\n",
    "           xticks=[0, int(_x.max()/2), _x.max()],\n",
    "           xticklabels=[0, int(_x.max()/2), _x.max()],\n",
    "           # yticks=[],\n",
    "           # yticklabels=[],\n",
    "          )\n",
    "\n",
    "    fig.supxlabel('iterations')\n",
    "    fig.tight_layout()\n",
    "    sns.despine()\n",
    "\n",
    "    # fig_name = os.path.join('figures', '03_1_loss.png')\n",
    "    # fig.savefig(fig_name, dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67f4658-9315-4230-9939-32d6283fd22c",
   "metadata": {},
   "source": [
    "## Evaluating the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e8c9aa-10c8-41dd-b72f-50ac29323b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data = pd.read_csv(os.path.join(PATH_PROC_DATA, 'pDeltaT_clean.csv'))\n",
    "\n",
    "X_eval = true_data[features]\n",
    "y_eval = true_data[target].to_numpy() / 100\n",
    "\n",
    "X_eval_scaled = scaler.transform(X_eval)\n",
    "\n",
    "y_pred = model.predict(X_eval_scaled)\n",
    "rmse = np.sqrt(mean_squared_error(y_eval, y_pred.ravel()))\n",
    "\n",
    "y_resid = (y_eval - y_pred.ravel())\n",
    "ape = np.abs(y_resid) / y_eval\n",
    "mape = np.mean(ape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722fd050-300c-4b6f-a95c-11ec90826b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = sns.color_palette('rocket', 2)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4.5, 4))\n",
    "ax = sns.histplot(x=ape,\n",
    "                  color=cs[0], stat='density', kde=True, ax=ax,\n",
    "                  line_kws={'lw': 2})\n",
    "ax.vlines(mape, *ax.get_ybound(), colors=cs[1], ls='--',\n",
    "          label='mean absolute error')\n",
    "ax.legend()\n",
    "ax.set(xlabel='', ylabel='',\n",
    "       xticks=[0, mape, int(ax.get_xbound()[1] / 2), int(ax.get_xbound()[1])],\n",
    "       xticklabels=[0, round(mape, 2), int(ax.get_xbound()[1] / 2), int(ax.get_xbound()[1])],\n",
    "       xlim=[0, int(ax.get_xbound()[1])],\n",
    "       yticks=[0, 0.18, 0.36],\n",
    "       yticklabels=[0, 0.18, 0.36],\n",
    "       ylim=[0, 0.36]\n",
    "      )\n",
    "\n",
    "fig.supxlabel('absolute error [\\%]')\n",
    "fig.supylabel('probability density')\n",
    "fig.tight_layout()\n",
    "sns.despine()\n",
    "\n",
    "# fig_name = os.path.join('figures', '03_2_ape_dist.png')\n",
    "# fig.savefig(fig_name, dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00686eb0-48a8-40f1-92e0-4e15c64ce6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
